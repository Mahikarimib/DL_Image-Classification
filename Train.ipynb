{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": " Train.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO6IpsbScXFFhq4Ts5acIuG"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "def train_one_epoch(model, dataloder, criterion, optimizer, device):    \n",
        "    model.train()\n",
        "        \n",
        "    steps = len(dataloder.dataset) // dataloder.batch_size\n",
        "    \n",
        "    running_loss = 0.0\n",
        "    running_corrects = 0\n",
        "    \n",
        "    for i, (inputs, labels) in enumerate(dataloder):\n",
        "        \n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        \n",
        "        # forward\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        \n",
        "        # backward\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        \n",
        "        # update parameters\n",
        "        optimizer.step()\n",
        "        \n",
        "        # statistics\n",
        "        running_loss  = (running_loss * i + loss.item()) / (i + 1)\n",
        "        running_corrects += torch.sum(outputs.argmax(1) == labels)\n",
        "        \n",
        "        # report\n",
        "        sys.stdout.flush()\n",
        "        sys.stdout.write(\"\\r  Step %d/%d | Loss: %.5f\" % (i, steps, loss.item()))\n",
        "        \n",
        "    epoch_loss = running_loss\n",
        "    epoch_acc = running_corrects / len(dataloder.dataset)\n",
        "    \n",
        "    sys.stdout.flush()\n",
        "    print('\\r{} Loss: {:.5f} Acc: {:.5f}'.format('  train', epoch_loss, epoch_acc))\n",
        "    \n",
        "    return model\n",
        "\n",
        "    \n",
        "def validate_model(model, dataloder, criterion, device):\n",
        "    model.eval()\n",
        "    \n",
        "    steps = len(dataloder.dataset) // dataloder.batch_size\n",
        "    \n",
        "    running_loss = 0.0\n",
        "    running_corrects = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for i, (inputs, labels) in enumerate(dataloder):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            # forward\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # statistics\n",
        "            running_loss  = (running_loss * i + loss.item()) / (i + 1)\n",
        "            running_corrects += torch.sum(outputs.argmax(1) == labels)\n",
        "\n",
        "            # report\n",
        "            sys.stdout.flush()\n",
        "            sys.stdout.write(\"\\r  Step %d/%d | Loss: %.5f\" % (i, steps, loss.item()))\n",
        "        \n",
        "    epoch_loss = running_loss\n",
        "    epoch_acc = running_corrects / len(dataloder.dataset)\n",
        "    \n",
        "    sys.stdout.flush()\n",
        "    print('\\r{} Loss: {:.5f} Acc: {:.5f}'.format('  valid', epoch_loss, epoch_acc))\n",
        "    \n",
        "    return epoch_acc\n",
        "\n",
        "\n",
        "def train_model(model, train_dl, valid_dl, criterion, optimizer, device,\n",
        "                scheduler=None, num_epochs=10):\n",
        "\n",
        "    if not os.path.exists('models'):\n",
        "        os.mkdir('models')\n",
        "    \n",
        "    device = device or torch.device('cpu')\n",
        "\n",
        "    since = time.time()\n",
        "       \n",
        "    best_model_wts = model.state_dict()\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch + 1, num_epochs))\n",
        "        print('-' * 10)\n",
        "\n",
        "        ## train and validate\n",
        "        model = train_one_epoch(model, train_dl, criterion, optimizer, device)\n",
        "        val_acc = validate_model(model, valid_dl, criterion, device)\n",
        "        if scheduler is not None:\n",
        "            scheduler.step()\n",
        "       \n",
        "        # deep copy the model\n",
        "        if val_acc > best_acc:\n",
        "            best_acc = val_acc\n",
        "            best_model_wts = model.state_dict()\n",
        "            torch.save(best_model_wts, \"./models/epoch-{}-acc-{:.5f}.pth\".format(epoch, best_acc))\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:.4f}'.format(best_acc))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model"
      ],
      "metadata": {
        "id": "GOAD6RQo4M6g"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}