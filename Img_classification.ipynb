{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Img classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO8Ri/vwp2wtd9YGui/QdtC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mahikarimib/Image-Classification/blob/main/Img_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Libraries"
      ],
      "metadata": {
        "id": "wHnPUW7qxA9f"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3SqlY4m_xpkI"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import time\n",
        "import os\n",
        "import glob\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "import torchvision\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# Our libraries\n",
        "from train import train_model\n",
        "from model_utils import *\n",
        "from predict_utils import *\n",
        "from vis_utils import *\n",
        "\n",
        "# some initial setup\n",
        "np.set_printoptions(precision=2)\n",
        "np.random.seed(1234)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data"
      ],
      "metadata": {
        "id": "HGFujX_zxK4m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_DIR = 'D:/datasets/catsvsdogs/dev/'\n",
        "sz = 224\n",
        "batch_size = 32"
      ],
      "metadata": {
        "id": "h-Yhtdoxx11T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.listdir(DATA_DIR)"
      ],
      "metadata": {
        "id": "uXfEaKU6x-YQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trn_dir = f'{DATA_DIR}train'\n",
        "val_dir = f'{DATA_DIR}valid'"
      ],
      "metadata": {
        "id": "vHn4L-WEyDWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.listdir(trn_dir)"
      ],
      "metadata": {
        "id": "bolbrqq-yDzz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trn_fnames = glob.glob(f'{trn_dir}/*/*.jpg')\n",
        "trn_fnames[:5]"
      ],
      "metadata": {
        "id": "g7MXE6PXySfz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img = plt.imread(trn_fnames[3])\n",
        "plt.imshow(img);"
      ],
      "metadata": {
        "id": "wRb6xfWRySyj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = datasets.ImageFolder(trn_dir)"
      ],
      "metadata": {
        "id": "sNKsLH1QyTDc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds.class_to_idx"
      ],
      "metadata": {
        "id": "tJC32nCIyTOJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transformations"
      ],
      "metadata": {
        "id": "0Stwoi5fw9eS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tfms = transforms.Compose([\n",
        "    transforms.Resize((sz, sz)),  # PIL Image\n",
        "    transforms.ToTensor(),        # Tensor\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "train_ds = datasets.ImageFolder(trn_dir, transform=tfms)\n",
        "valid_ds = datasets.ImageFolder(val_dir, transform=tfms)"
      ],
      "metadata": {
        "id": "JaLwYESHe5K4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "DataLoader"
      ],
      "metadata": {
        "id": "E78mwDtZw0vh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dl = torch.utils.data.DataLoader(train_ds, \n",
        "                                       batch_size=batch_size, \n",
        "                                       shuffle=True, \n",
        "                                       num_workers=8)\n",
        "\n",
        "valid_dl = torch.utils.data.DataLoader(valid_ds, \n",
        "                                       batch_size=batch_size, \n",
        "                                       shuffle=False, \n",
        "                                       num_workers=8)"
      ],
      "metadata": {
        "id": "yHGQ1vfSe5cX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs, targets = next(iter(train_dl))\n",
        "out = torchvision.utils.make_grid(inputs, padding=3)\n",
        "plt.figure(figsize=(16, 12))\n",
        "imshow(out, title='Random images from training data')"
      ],
      "metadata": {
        "id": "hdj_PScbe5lq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model : CNN"
      ],
      "metadata": {
        "id": "7rqN_h81wxGB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleCNN(nn.Module):\n",
        "    \n",
        "    def __init__(self):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        \n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 16, kernel_size=5, padding=2),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2)\n",
        "        )\n",
        "        \n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.Conv2d(16, 32, kernel_size=5, padding=2),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2)\n",
        "        )\n",
        "        \n",
        "        self.fc = nn.Linear(56 * 56 * 32, 2)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        out = self.conv1(x)\n",
        "        out = self.conv2(out)            # (bs, C, H,  W)\n",
        "        out = out.view(out.size(0), -1)  # (bs, C * H, W)\n",
        "        out = self.fc(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "fh3D4d2Le5rO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = SimpleCNN()"
      ],
      "metadata": {
        "id": "2qRXvL0Se5vU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loss function and optimizer"
      ],
      "metadata": {
        "id": "X9OfaxH_woKS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.002, momentum=0.9)"
      ],
      "metadata": {
        "id": "QiTHhBDIl9dk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train"
      ],
      "metadata": {
        "id": "Dp7wY-eZwi9X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 10\n",
        "losses = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (inputs, targets) in enumerate(train_dl):\n",
        "        inputs = to_var(inputs)\n",
        "        targets = to_var(targets)\n",
        "        \n",
        "        # forwad pass\n",
        "        outputs = model(inputs)\n",
        "        \n",
        "        # loss\n",
        "        loss = criterion(outputs, targets)\n",
        "        losses.append(loss.item())\n",
        "\n",
        "        # backward pass\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        \n",
        "        # update parameters\n",
        "        optimizer.step()\n",
        "        \n",
        "        # report\n",
        "        if (i + 1) % 50 == 0:\n",
        "            print('Epoch [%2d/%2d], Step [%3d/%3d], Loss: %.4f'\n",
        "                  % (epoch + 1, num_epochs, i + 1, len(train_ds) // batch_size, loss.item()))"
      ],
      "metadata": {
        "id": "i6QU5JdUCUBv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 4))\n",
        "plt.plot(losses)\n",
        "plt.xlabel('Iteration')\n",
        "plt.ylabel('loss')\n",
        "plt.title('Cross Entropy Loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8uaTVF7HCUaf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Analyze results"
      ],
      "metadata": {
        "id": "GIgN7I6WJsbe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accuracy on validation data"
      ],
      "metadata": {
        "id": "Fj3gLJ-DJuiO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, dataloader):\n",
        "    model.eval()  # for batch normalization layers\n",
        "    corrects = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for inputs, targets in dataloader:\n",
        "            inputs, targets = to_var(inputs, True), to_var(target, True)\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            corrects += (preds == targets.data).sum()\n",
        "    \n",
        "    print('accuracy: {:.2f}'.format(100. * corrects / len(dataloader.dataset)))"
      ],
      "metadata": {
        "id": "dNMvuX4SCUoU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_model(model, valid_dl)"
      ],
      "metadata": {
        "id": "kPmBp5z6CU0h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_model(model, train_dl)"
      ],
      "metadata": {
        "id": "X-sTYZjwCVCl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "visualize_model(model, train_dl)"
      ],
      "metadata": {
        "id": "Gm1ywudNdz_A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "visualize_model(model, valid_dl)"
      ],
      "metadata": {
        "id": "HralIhB_d_kQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Confusion matrix"
      ],
      "metadata": {
        "id": "f3vyFUpke-05"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred, y_true = predict_class(model, valid_dl)\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "plot_confusion_matrix(cm, train_ds.classes, normalize=True, figsize=(4, 4))"
      ],
      "metadata": {
        "id": "XDO_afcPeANz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Solving Overfit\n",
        "\n",
        "1)Data Augmentation"
      ],
      "metadata": {
        "id": "IPHLn-WVuajR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data augmentation and normalization for training\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.Resize((sz, sz)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ColorJitter(0.1, 0.1, 0.1, 0.01),\n",
        "    transforms.RandomRotation(20),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Just normalization for validation\n",
        "valid_transforms = transforms.Compose([\n",
        "    transforms.Resize((sz, sz)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "train_ds = datasets.ImageFolder(f'{DATA_DIR}train', train_transforms)\n",
        "valid_ds = datasets.ImageFolder(f'{DATA_DIR}valid', valid_transforms)\n",
        "\n",
        "train_dl = torch.utils.data.DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
        "valid_dl = torch.utils.data.DataLoader(valid_ds, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "train_ds_sz = len(train_ds)\n",
        "valid_ds_sz = len(valid_ds)\n",
        "\n",
        "print('Train size: {}\\nValid size: {} ({:.2f})'.format(train_ds_sz, valid_ds_sz, valid_ds_sz/(train_ds_sz + valid_ds_sz)))\n",
        "\n",
        "class_names = train_ds.classes"
      ],
      "metadata": {
        "id": "XiZ5WYJZu7Ou"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs, targets = next(iter(train_dl))     # Get a batch of training data\n",
        "out = torchvision.utils.make_grid(inputs)  # Make a grid from batch\n",
        "plt.figure(figsize=(16., 12.))\n",
        "imshow(out, title='Augmented Images');"
      ],
      "metadata": {
        "id": "kh_ou1Lzu9Ha"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create model\n",
        "model = SimpleCNN()\n",
        "    \n",
        "# loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.002, momentum=0.9)\n",
        "\n",
        "# train\n",
        "model = train_model(model, train_dl, valid_dl, criterion, optimizer, num_epochs=5)"
      ],
      "metadata": {
        "id": "qqfBgtbNv0XY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2)Transfer Learning"
      ],
      "metadata": {
        "id": "dNounbhq_l5E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load pre-trained ResNet\n",
        "model = load_pretrained_resnet50(model_path=None, num_classes=2)\n",
        "\n",
        "# loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.002, momentum=0.9)\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.9)"
      ],
      "metadata": {
        "id": "GM_zrU5Rv1DG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = train_model(model, train_dl, valid_dl, criterion, optimizer, scheduler, num_epoches=2)"
      ],
      "metadata": {
        "id": "O3wVkPu0_ytf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_model(model, valid_dl)"
      ],
      "metadata": {
        "id": "QhoeNM63Akqj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "visualize_model(model, valid_dl, num_images=6)"
      ],
      "metadata": {
        "id": "YRrnhVCFA3bL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_errors(model, valid_dl)"
      ],
      "metadata": {
        "id": "hQvBtNspA_P2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}